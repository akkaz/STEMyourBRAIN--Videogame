# ========================================
# LLM Provider Configuration
# ========================================

# Select active LLM provider: groq, gemini, openai, anthropic
# Change this to switch between different AI models
LLM_PROVIDER=groq

# Model Configuration
# Adjust these based on your chosen provider (see examples below)
LLM_MODEL=llama-3.3-70b-versatile
LLM_MODEL_SUMMARY=llama-3.1-8b-instant
LLM_MODEL_CONTEXT_SUMMARY=llama-3.1-8b-instant

# ========================================
# API Keys (configure only what you need)
# ========================================

# Groq - Fast inference with Llama models (free tier available)
# Required if LLM_PROVIDER=groq
GROQ_API_KEY=

# Google Gemini - Google's Gemini models
# Required if LLM_PROVIDER=gemini
# Get your key at: https://aistudio.google.com/apikey
GEMINI_API_KEY=

# OpenAI - GPT models
# Required if LLM_PROVIDER=openai, or for Module 5 evaluation
OPENAI_API_KEY=

# Anthropic - Claude models
# Required if LLM_PROVIDER=anthropic
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# ========================================
# Opik & Comet ML Configuration
# ========================================

# Required with Module 5 (optional: for evaluation and LLMOps)
# Make sure to restart the Docker infrastructure after setting this up.
COMET_API_KEY=

# Optional: Prompt versioning for Opik (default: v1)
# Change this value (e.g., v2, v3) to update prompts in Opik without rebuilding
# After changing, restart the API container: docker-compose restart philoagents-api
PROMPT_VERSION=v1

# ========================================
# Example Configurations by Provider
# ========================================

# For Gemini (recommended for free tier):
# LLM_PROVIDER=gemini
# LLM_MODEL=gemini-2.0-flash-exp
# LLM_MODEL_SUMMARY=gemini-1.5-flash
# LLM_MODEL_CONTEXT_SUMMARY=gemini-1.5-flash
# GEMINI_API_KEY=your_gemini_api_key

# For OpenAI:
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o
# LLM_MODEL_SUMMARY=gpt-4o-mini
# LLM_MODEL_CONTEXT_SUMMARY=gpt-4o-mini
# OPENAI_API_KEY=your_openai_api_key

# For Anthropic Claude:
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-5-sonnet-20241022
# LLM_MODEL_SUMMARY=claude-3-5-haiku-20241022
# LLM_MODEL_CONTEXT_SUMMARY=claude-3-5-haiku-20241022
# ANTHROPIC_API_KEY=your_anthropic_api_key

# For Groq (default - current setup):
# LLM_PROVIDER=groq
# LLM_MODEL=llama-3.3-70b-versatile
# LLM_MODEL_SUMMARY=llama-3.1-8b-instant
# LLM_MODEL_CONTEXT_SUMMARY=llama-3.1-8b-instant
# GROQ_API_KEY=your_groq_api_key
